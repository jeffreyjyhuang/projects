{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Linear-Regression:-Gradient-Descent\" data-toc-modified-id=\"Linear-Regression:-Gradient-Descent-1\">Linear Regression: Gradient Descent</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Learning-Rate-Parameter\" data-toc-modified-id=\"Learning-Rate-Parameter-1.0.1\">Learning Rate Parameter</a></span></li><li><span><a href=\"#Convex-Functions\" data-toc-modified-id=\"Convex-Functions-1.0.2\">Convex Functions</a></span></li><li><span><a href=\"#Scaling\" data-toc-modified-id=\"Scaling-1.0.3\">Scaling</a></span></li></ul></li></ul></li><li><span><a href=\"#Implementing-Gradient-Descent\" data-toc-modified-id=\"Implementing-Gradient-Descent-2\">Implementing Gradient Descent</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Batch-Gradient-Descent\" data-toc-modified-id=\"Batch-Gradient-Descent-2.0.1\">Batch Gradient Descent</a></span></li><li><span><a href=\"#Stochastic-Gradient-Descent\" data-toc-modified-id=\"Stochastic-Gradient-Descent-2.0.2\">Stochastic Gradient Descent</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: Gradient Descent\n",
    "\n",
    "We've looked at the Linear Regression model, and a method to minimize the cost function. We're pretty much all set to start playing with data and fitting a Linear Regression model. However, when we actually go about that, we find that our model doesn't scale well with bigger datasets. Even though our Normal Equation is a nice and tidy equation that we can plug into, it doesn't work well in some edge cases, and it's computationally expensive. Instead, we'll look a more complicated (but more efficient) way of minimizing our cost function: Gradient Descent.\n",
    "\n",
    "Imagine that you are blindfolded and lost somewhere on a mountain. You know that the parking lot is on sea level, so you use your feet to guide you towards downhill. To optimize this, you go towards the direction that is the **steepest part of the slope**. If you take a big, steep step, then you know that you're going the right direction.  This is the idea of Gradient Descent. We want to minimize $\\theta$, so we want to go towards the direction of the steepest part of the slope, so we get to our minimum $\\theta$ as soon as possible. This is equivalent to measuring the local gradient of the error function (with regard to our $\\theta$). Once the gradient is 0, then we have reached our minimum.\n",
    "\n",
    "In practice, Gradient Descent is a bit more efficient. It begins by filling up $\\theta$ with a bunch of random values, and then slowly improving each point on each iteration. This keeps going until we **converge** on the minimum. \n",
    "\n",
    "[Illustration of Gradient Descent]\n",
    "\n",
    "### Learning Rate Parameter\n",
    "\n",
    "A parameter that is always needed for Gradient Descent is the learning rate. This parameter determines how 'fast' we want our Gradient Descent to learn in each iteration. If the learning rate is too low, then our algorithm may take too long to converge to a minimum. But if our learning rate is too high, then our algorithm might diverge with larger and larger values, and fail to find a good solution.\n",
    "\n",
    "[Learning Rate Picture]\n",
    "\n",
    "### Convex Functions\n",
    "\n",
    "Another thing to note when creating a Gradient Descent algorithm is that our function might look weird, and so our algorithm may find the wrong minimum. For example, if our function had a global minimum but also a different local minimum, our algorithm might think that the local minimum is a global one (depending on where the random iterations are). Take a look at this:\n",
    "\n",
    "[Illustration of Gradient Descent Pitfalls]\n",
    "\n",
    "Thankfully, our MSE cost function will always be a convex function. This means that our function will never have a local minimum, and only a single global minimum. Whew. A convex cost function also means that our function is nice and pretty with no abrupt slope changes. This means that if the learning rate is not too high, and that we wait long enough, we will always converge to a minimum. \n",
    "\n",
    "### Scaling\n",
    "\n",
    "Lastly, it is important to scale our data. Because Gradient Descent algorithms always go straight to the minimum, it performs slower on unscaled data. You can imagine going down a short hill versus a big ravine - the ravine is long and narrow (the unscaled features), while the short hill is circular and scaled.\n",
    "\n",
    "[Scaled vs Unscaled Features with Gradient Descent]\n",
    "\n",
    "# Implementing Gradient Descent\n",
    "\n",
    "Now that we have the big picture of gradient descent, let's look at the different ways to implement this. \n",
    "\n",
    "### Batch Gradient Descent\n",
    "Because we are looking for the direction towards the minimum, we need a way to know how much the cost function will change if we change $\\theta$ by a little bit. This is the work of a partial derivative. If we find the partial derivative of:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{MSE}(\\boldsymbol(X),h_\\theta) = \\frac{1}{m}\\sum_{i=1}^m\\big(\\boldsymbol\\theta^T \\boldsymbol{x}^{(i)}-y^{(i)}\\big)^2$$\n",
    "\n",
    "Partial Derivative:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial\\theta} = \\frac{2}{m}\\sum_{i=1}^{m} \\big( \\theta^T x^{(i)} -  y^{(i)} \\big) x_j^{(i)}\n",
    "$$\n",
    "\n",
    "or all at once (Gradient vector of the cost function): \n",
    "$$\n",
    "\\nabla_\\theta \\text{MSE}(\\theta) = \\begin{pmatrix} \\frac{\\partial}{\\partial\\theta_0}  \\text{MSE}(\\theta) \\\\ \\frac{\\partial}{\\partial\\theta_1}  \\text{MSE}(\\theta) \\\\ \\vdots \\\\ \\frac{\\partial}{\\partial\\theta_n}  \\text{MSE}(\\theta) \\end{pmatrix} = \\frac{2}{m} X^T (X\\theta - y)\n",
    "$$\n",
    "\n",
    "This is why it's called **batch gradient descent** - this formula takes a whole batch of training data points in each iteration of the algorithm. In turn, this is very slow when used on a large training set. However, this is a good starting point in learning about gradient descent, because the other implementations of it is derived from batch Gradient Descent.\n",
    "\n",
    "The next step to Gradient Descent is to go towards the direction of the minimum (downhill). This means that we need to subtract $\\nabla \\text{MSE}(\\theta)$ from $\\theta$. Mathematically, this is:\n",
    "\n",
    "$$ \\theta^{(next \\space step)} = \\theta - (learning\\space rate) \\nabla_\\theta\\text{MSE}(\\theta)$$\n",
    "\n",
    "This is where learning rate comes in, and it makes quite a bit of sense - we multiply the gradient vector to determine the size of the downhill step. The larger the learning rate, the bigger step we take.\n",
    "\n",
    "Let's implement Batch Gradient Descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent theta: [[4.4091403 ]\n",
      " [2.70370176]]\n",
      "\n",
      "Normal Equation theta: [[4.4091403 ]\n",
      " [2.70370176]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create some linear data\n",
    "X = 2 * np.random.rand(100,1)\n",
    "y = 4 + 3 * X + np.random.randn(100,1)\n",
    "X_b = np.c_[np.ones((100,1)), X] # creating a matrix full of 1's \n",
    "\n",
    "# Parameters for Gradient Descent\n",
    "eta = 0.1 # learning rate\n",
    "n_iterations = 1000 # number of iterations\n",
    "m = 100 # number of data points\n",
    "theta = np.random.randn(2,1) # random initialization \n",
    "\n",
    "# Implementing Gradient Descent\n",
    "for iteration in range(n_iterations): # for every iteration\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(theta)- y) # find partial derivative\n",
    "    theta = theta - eta * gradients # going towards direction of minimum \n",
    "    \n",
    "# Implementing Normal Equation\n",
    "norm_theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y) # theta = (X^TX)^-1 X^T y\n",
    "\n",
    "\n",
    "print(f\"Gradient Descent theta: {theta}\")\n",
    "print(\"\")\n",
    "print(f\"Normal Equation theta: {norm_theta}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got exactly what the Normal Equation got! \n",
    "\n",
    "However, Gradient Descent has a bunch of parameters to tweak, and we can take advantage of this. We won't go into it yet, but this is what `gridsearching` will eventually do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "\n",
    "While Batch Gradient Descent takes the whole training set to compute the gradient at every iteration, Stochastic Gradient Descent picks a random instance in the training set at every iteration, and computes the gradient on that instance. It performs faster because there is only a single data point, and requires little memory to run the algorithm.\n",
    "\n",
    "However, because it's a stochastic method (random), it's quite hectic. The cost function may move around, and only decreases when you look at the average distance over time. Over time, it will eventually be very close to the minimum, but will never settle on a single point. Not only is it very cost-effective, but it can help the algorithm jump out of local minima in non-convex cost functions.\n",
    "\n",
    "So the trade-off is: the randomness of Stochastic Gradient Descent prevent us from getting stuck in unwanted local minima, but this means that our algorithm may never settle on a true minimum. A solution to this is to reduce the learning rate so that it helps settle on a global minimum. \n",
    "\n",
    "Scikit-Learn allows us to implement Stochastic Gradient Descent using `SGDRegressor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4.39944622]), array([2.73400806]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_reg = SGDRegressor(\n",
    "    max_iter=1000,# maximum iterations\n",
    "    tol=1e-3, # converges if loss is more than 0.001\n",
    "    penalty = None, # regularization (next section!)\n",
    "    eta0=0.1) # learning rate \n",
    "sgd_reg.fit(X,y.ravel())\n",
    "sgd_reg.intercept_, sgd_reg.coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jeffrey-huang",
   "language": "python",
   "name": "jeffrey-huang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
