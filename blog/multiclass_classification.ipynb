{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Multiclass-Cassification\" data-toc-modified-id=\"Multiclass-Cassification-1\">Multiclass Cassification</a></span><ul class=\"toc-item\"><li><span><a href=\"#Multilabel-Classification\" data-toc-modified-id=\"Multilabel-Classification-1.1\">Multilabel Classification</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Cassification\n",
    "We've taken a look at binary classifiers - a model that distinguishes between two classes. Now, we will look at multi-class classifiers, which are models that can distinguish between more than two classes. There are some classifiers that can do both binary and multi (`SGDClassifier`, `RandomForest`), but some are strictly binary (`LogisticRegression`, `SVM`). Let's take a look at why this is the case.\n",
    "\n",
    "Multi-class classifiers can work various ways. For example, if we took the MNIST dataset and wanted to create a model that could classify the images into 10 classes (0 to 9), we can take two approaches:\n",
    "- *One-versus-rest (OvR)*: Create 10 separate binary classifiers. Then, we take an input and run it through all 10 binary classifiers. The class that scores the highest performance score (i.e. the '3-detector') would be selected.\n",
    "- *One-versus-one (OvO)*: We train a binary classifier for every possible pair of classes. For example, we would train a classifier to distinguish between '0' and '1', and then '1', '2', and so on. Therefore, if there are $N$ classes, we create $N \\times (N-1) / 2$ binary classifiers. In this example, we would have to train 45 classifiers and see which class wins the most 'duels' in performance. \n",
    "    - An advantage of the this, is that each classifier only needs to be trained on the part of the training set that the two classes need to distinguish, rather than the whole thing. This means that it scales better with larger training sets, and it's faster to train many classifiers on small training sets. \n",
    "\n",
    "In the end, binary classifiers will prefer to adopt the first method (*one-versus-all*), while exclusive multi-class classifiers prefer to adopt the second (*one-versus-one*). You can customize your classifier using Scikit-Learn. All you have to do is to pass a classifier (binary or multi) through a constructor. \n",
    "\n",
    "Let's take a support vector machine classifier as an example. I'm not going to get into support vector machines yet, but SVC's scale poorly with larger training sets. One-vs-One is preferred, but we can actually change this ourselves. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 2, 0, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC (one-vs-one)\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, \n",
    "                           n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
    "\n",
    "# define model\n",
    "model = SVC(decision_function_shape='ovo') # one-vs-one\n",
    "\n",
    "# fit model\n",
    "model.fit(X, y)\n",
    "\n",
    "# make predictions\n",
    "model.predict(X)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 2, 0, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC (one-vs-rest)\n",
    "\n",
    "# additional libraries\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10,\n",
    "                           n_informative=5, n_redundant=5, n_classes=3, random_state=1)\n",
    "\n",
    "# changing strategy\n",
    "ovr_svc = OneVsRestClassifier(SVC())\n",
    "\n",
    "# fit model\n",
    "ovr_svc.fit(X, y)\n",
    "\n",
    "# make predictions\n",
    "ovr_svc.predict(X)[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel Classification\n",
    "\n",
    "So far, we've looked at models that classify data points to a single label. However, there are instances in which we might want to classify multiple labels for a single data point. For example, if we built a face recognition software to classify the faces of Alice, Bob, and Charlie, a single-label-classifier can only consider pictures that contain only one face. However, a multi-label classifier can classify a picture of Alice and Charlie, with an output of $[1,0,1]$. \n",
    "\n",
    "Take a KNN classifier for an example. Say that we want to create a classifier that tells us if a digit/image is a large number, an odd number, or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data collection (don't show)\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()\n",
    "y = y.astype(np.uint8)\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "y_train_large = (y_train >= 7) # large number\n",
    "y_train_odd = (y_train % 2 == 1) # odd number\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd] # creating multi-label\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_multilabel)\n",
    "\n",
    "knn_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this chunk of code, `y_multilabel` has created two target labels for each datapoint (image). The output seems to make sense - the number 5 is not large, but is an odd number. \n",
    "\n",
    "Evaluating multi-label classifiers are also quite similar to evaluating other classifiers. Of course, it depends on the problem and what we are looking for, but a common one is to use the $F_1$ score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9420401854714066"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)\n",
    "f1_score(y_multilabel, y_train_knn_pred, average=\"macro\", zero_division = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jeffrey-huang",
   "language": "python",
   "name": "jeffrey-huang"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
